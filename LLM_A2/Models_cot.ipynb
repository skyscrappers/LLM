{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"489f5e7ced0d4b5dba7c59ccd848eccb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a2e94a0e281b45949030fbdbfce8f883","IPY_MODEL_70a5f08681434a889f945b9cc5421a18","IPY_MODEL_849ee2c23bd141f7982473dd5a179d20"],"layout":"IPY_MODEL_fe70984aa9ed4a8fbf2e43e64ed28be6"}},"a2e94a0e281b45949030fbdbfce8f883":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8f28bd4a48a446938effc33e45c60f57","placeholder":"​","style":"IPY_MODEL_eb56df4e4a094af9bffaa72e3ec62ade","value":"Loading checkpoint shards: 100%"}},"70a5f08681434a889f945b9cc5421a18":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_67eaec48adee4bd2802a07374a0528b2","max":4,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6284f8d8bb414b2fbb016c4570d85c55","value":4}},"849ee2c23bd141f7982473dd5a179d20":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ed660e050f4b454288a88df5dd2299c0","placeholder":"​","style":"IPY_MODEL_274f524006d64c3cbfdbbcb036ce33a8","value":" 4/4 [01:16&lt;00:00, 16.51s/it]"}},"fe70984aa9ed4a8fbf2e43e64ed28be6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8f28bd4a48a446938effc33e45c60f57":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eb56df4e4a094af9bffaa72e3ec62ade":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"67eaec48adee4bd2802a07374a0528b2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6284f8d8bb414b2fbb016c4570d85c55":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ed660e050f4b454288a88df5dd2299c0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"274f524006d64c3cbfdbbcb036ce33a8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ad56d8400207459d83da899ae5d2785d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fdf5cddce7d64bbeb936991983ec4f51","IPY_MODEL_cb9b7741307d45ce9c586c0efa547cca","IPY_MODEL_b1ed3baac33b4aa2ac79b835ed9336d1"],"layout":"IPY_MODEL_24988250c1ff4dd3afed146d6712d24b"}},"fdf5cddce7d64bbeb936991983ec4f51":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6bf7d79d806447fb99c0404b584e3ff0","placeholder":"​","style":"IPY_MODEL_52b61171ec654209b43666ea8be662a7","value":"Loading checkpoint shards: 100%"}},"cb9b7741307d45ce9c586c0efa547cca":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f94fbb248dd14a8692ef264520511ab9","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fd13f5c81b50496090656466e1ebe8ce","value":2}},"b1ed3baac33b4aa2ac79b835ed9336d1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4703c2d74de842879ec0c7a2850e1559","placeholder":"​","style":"IPY_MODEL_ed1fd931bc32413ebb0e18a664464c2d","value":" 2/2 [00:37&lt;00:00, 17.88s/it]"}},"24988250c1ff4dd3afed146d6712d24b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6bf7d79d806447fb99c0404b584e3ff0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"52b61171ec654209b43666ea8be662a7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f94fbb248dd14a8692ef264520511ab9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fd13f5c81b50496090656466e1ebe8ce":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4703c2d74de842879ec0c7a2850e1559":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ed1fd931bc32413ebb0e18a664464c2d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9c70099f3aa54ab8b582dcda4d829c01":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6b7f0bd46fb9476db41d92f18d286863","IPY_MODEL_a79d786f23dc4a07b28731e7f7b4828e","IPY_MODEL_ff7d082b25d24c86923fcfb08e41e984"],"layout":"IPY_MODEL_8525bc37d6ca44daa5bc6466e9a12b58"}},"6b7f0bd46fb9476db41d92f18d286863":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1012ef89c4784c1da84dac0664432ed3","placeholder":"​","style":"IPY_MODEL_e56928616e0b453c92ca024128cde77e","value":"Loading checkpoint shards: 100%"}},"a79d786f23dc4a07b28731e7f7b4828e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ca97228d8bfb47ebb1037bea599e0a82","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dd17fc3443264074bc663ae0d4e0f1b9","value":2}},"ff7d082b25d24c86923fcfb08e41e984":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_31094c09960047cdb877880bafffb401","placeholder":"​","style":"IPY_MODEL_a8ec691a7dbf4f3c8390901f7b383730","value":" 2/2 [00:08&lt;00:00,  3.75s/it]"}},"8525bc37d6ca44daa5bc6466e9a12b58":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1012ef89c4784c1da84dac0664432ed3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e56928616e0b453c92ca024128cde77e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ca97228d8bfb47ebb1037bea599e0a82":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dd17fc3443264074bc663ae0d4e0f1b9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"31094c09960047cdb877880bafffb401":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a8ec691a7dbf4f3c8390901f7b383730":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q langchain\n!pip install git+https://github.com/huggingface/transformers.git\n!pip install git+https://github.com/huggingface/accelerate.git\n!pip install bitsandbytes","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","colab":{"base_uri":"https://localhost:8080/"},"id":"l7o15ZFG1yvx","outputId":"8979b2ff-faec-4457-e3af-8e0355903264","execution":{"iopub.status.busy":"2024-09-18T18:04:23.973335Z","iopub.execute_input":"2024-09-18T18:04:23.973984Z","iopub.status.idle":"2024-09-18T18:06:24.342795Z","shell.execute_reply.started":"2024-09-18T18:04:23.973943Z","shell.execute_reply":"2024-09-18T18:06:24.341675Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 24.8.2 requires cubinlinker, which is not installed.\ncudf 24.8.2 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 24.8.2 requires ptxcompiler, which is not installed.\ncuml 24.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 24.8.2 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 24.8.2 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.6.0 which is incompatible.\ndistributed 2024.7.1 requires dask==2024.7.1, but you have dask 2024.8.1 which is incompatible.\ngoogle-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 24.1 which is incompatible.\njupyterlab 4.2.4 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nmomepy 0.7.2 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\nosmnx 1.9.4 requires shapely<2.1,>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\npointpats 2.5.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\nrapids-dask-dependency 24.8.0a0 requires dask==2024.7.1, but you have dask 2024.8.1 which is incompatible.\nspaghetti 1.7.6 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nspopt 0.6.1 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nydata-profiling 4.9.0 requires scipy<1.14,>=1.4.1, but you have scipy 1.14.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mCollecting git+https://github.com/huggingface/transformers.git\n  Cloning https://github.com/huggingface/transformers.git to /tmp/pip-req-build-h2t207ep\n  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/pip-req-build-h2t207ep\n  Resolved https://github.com/huggingface/transformers.git to commit 5af7d41e49bbfc8319f462eb45253dcb3863dfb7\n  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.45.0.dev0) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers==4.45.0.dev0) (0.24.6)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.45.0.dev0) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.45.0.dev0) (24.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.45.0.dev0) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.45.0.dev0) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.45.0.dev0) (2.32.3)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers==4.45.0.dev0) (0.19.1)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.45.0.dev0) (0.4.4)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.45.0.dev0) (4.66.4)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.45.0.dev0) (2024.6.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.45.0.dev0) (4.12.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.45.0.dev0) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.45.0.dev0) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.45.0.dev0) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.45.0.dev0) (2024.7.4)\nBuilding wheels for collected packages: transformers\n  Building wheel for transformers (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for transformers: filename=transformers-4.45.0.dev0-py3-none-any.whl size=9761399 sha256=d255a3a9249cdd388c36e5190d84b5f44fde8c72cf9d7f335c2070d51ff2f04e\n  Stored in directory: /tmp/pip-ephem-wheel-cache-ap2lijtv/wheels/e7/9c/5b/e1a9c8007c343041e61cc484433d512ea9274272e3fcbe7c16\nSuccessfully built transformers\nInstalling collected packages: transformers\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.44.0\n    Uninstalling transformers-4.44.0:\n      Successfully uninstalled transformers-4.44.0\nSuccessfully installed transformers-4.45.0.dev0\nCollecting git+https://github.com/huggingface/accelerate.git\n  Cloning https://github.com/huggingface/accelerate.git to /tmp/pip-req-build-zioz2kuj\n  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/accelerate.git /tmp/pip-req-build-zioz2kuj\n  Resolved https://github.com/huggingface/accelerate.git to commit 4305033f8035defad0a87cd38e5c918e78510ba5\n  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: numpy<3.0.0,>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.35.0.dev0) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.35.0.dev0) (24.1)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate==0.35.0.dev0) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate==0.35.0.dev0) (6.0.2)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.35.0.dev0) (2.4.0)\nRequirement already satisfied: huggingface-hub>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.35.0.dev0) (0.24.6)\nRequirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.35.0.dev0) (0.4.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate==0.35.0.dev0) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate==0.35.0.dev0) (2024.6.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate==0.35.0.dev0) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate==0.35.0.dev0) (4.66.4)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate==0.35.0.dev0) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.35.0.dev0) (1.13.2)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.35.0.dev0) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.35.0.dev0) (3.1.4)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate==0.35.0.dev0) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate==0.35.0.dev0) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate==0.35.0.dev0) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate==0.35.0.dev0) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate==0.35.0.dev0) (2024.7.4)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate==0.35.0.dev0) (1.3.0)\nBuilding wheels for collected packages: accelerate\n  Building wheel for accelerate (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for accelerate: filename=accelerate-0.35.0.dev0-py3-none-any.whl size=330627 sha256=c42aa608f0332cf2820101da6445805e2df000bdecca0166c1192f894e5ca2f0\n  Stored in directory: /tmp/pip-ephem-wheel-cache-s70ukxpz/wheels/9c/a3/1e/47368f9b6575655fe9ee1b6350cfa7d4b0befe66a35f8a8365\nSuccessfully built accelerate\nInstalling collected packages: accelerate\n  Attempting uninstall: accelerate\n    Found existing installation: accelerate 0.33.0\n    Uninstalling accelerate-0.33.0:\n      Successfully uninstalled accelerate-0.33.0\nSuccessfully installed accelerate-0.35.0.dev0\nCollecting bitsandbytes\n  Downloading bitsandbytes-0.43.3-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (2.4.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (1.26.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (1.13.2)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (2024.6.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->bitsandbytes) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->bitsandbytes) (1.3.0)\nDownloading bitsandbytes-0.43.3-py3-none-manylinux_2_24_x86_64.whl (137.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.5/137.5 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: bitsandbytes\nSuccessfully installed bitsandbytes-0.43.3\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install -q langchain_community\nimport warnings\nfrom langchain import HuggingFacePipeline\nfrom langchain import LLMChain, PromptTemplate\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\n\nwarnings.filterwarnings('ignore')\n!pip install transformers huggingface_hub\n\nfrom huggingface_hub import login\n\n# Login with your API token\nlogin(\"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\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YppJyG5k1yvz","outputId":"b88103dd-c6a0-40b2-a27c-169f464626ab","execution":{"iopub.status.busy":"2024-09-18T18:09:41.851134Z","iopub.execute_input":"2024-09-18T18:09:41.851539Z","iopub.status.idle":"2024-09-18T18:10:15.514518Z","shell.execute_reply.started":"2024-09-18T18:09:41.851505Z","shell.execute_reply":"2024-09-18T18:10:15.513364Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.45.0.dev0)\nRequirement already satisfied: huggingface_hub in /opt/conda/lib/python3.10/site-packages (0.24.6)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (24.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.1)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.4)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (2024.6.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (4.12.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.7.4)\nThe token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: write).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}]},{"cell_type":"code","source":"import transformers\nimport torch\n\nllama_id = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n\npipeline1 = transformers.pipeline(\n    \"text-generation\",\n    model=llama_id,\n    model_kwargs={\"torch_dtype\": torch.bfloat16, \"quantization_config\" : {\"load_in_4bit\": True}},\n    device_map=\"auto\",\n\n)\n\ndef llama_output(prompt, tokens):\n    messages = [\n        {\"role\": \"user\", \"content\": prompt},\n    ]\n#     print(messages)\n    outputs = pipeline1(\n        messages,\n        max_new_tokens=tokens,\n    )\n    return outputs[0][\"generated_text\"][-1][\"content\"]\n","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["489f5e7ced0d4b5dba7c59ccd848eccb","a2e94a0e281b45949030fbdbfce8f883","70a5f08681434a889f945b9cc5421a18","849ee2c23bd141f7982473dd5a179d20","fe70984aa9ed4a8fbf2e43e64ed28be6","8f28bd4a48a446938effc33e45c60f57","eb56df4e4a094af9bffaa72e3ec62ade","67eaec48adee4bd2802a07374a0528b2","6284f8d8bb414b2fbb016c4570d85c55","ed660e050f4b454288a88df5dd2299c0","274f524006d64c3cbfdbbcb036ce33a8"]},"id":"FM05qq4_1yvz","outputId":"f0cc9f6c-e0f1-489d-beff-ee68c4b8d5ad","execution":{"iopub.status.busy":"2024-09-18T18:10:46.741152Z","iopub.execute_input":"2024-09-18T18:10:46.741715Z","iopub.status.idle":"2024-09-18T18:14:06.867584Z","shell.execute_reply.started":"2024-09-18T18:10:46.741679Z","shell.execute_reply":"2024-09-18T18:14:06.866804Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/855 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"04026478661743aeafc487b9989b488e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe84c1b100544879aec5e2d6a1f252e3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c9b2f20b60d4f3aa42f3efd900ced77"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"890cc93867cf485e8948a0624e7dde8e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ef9cc5cbff94cc58eb7d07a9b193395"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d1c5ddcf887548eaa64dffda14d563eb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fed8d2fc068a47b3b9a7864eeac480d2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"945ec18f4fbb411dbf9c31ceaa11ab28"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/184 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"10e0f247823b47d1914b08f521fc725f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/55.4k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"43a8a14471fc4230a8433cb05cc4b1e1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f813db349de64ce39873a5bd89e7bcf1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/296 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ce6f5372cdc445895ad994ed614cc8a"}},"metadata":{}}]},{"cell_type":"code","source":"llama_output(\"who is prime minister?\", 20)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":72},"id":"8e2L1le35zbn","outputId":"2bc84b47-bf2e-4363-ad7e-b2f9bd95a226"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":"[{'role': 'user', 'content': 'who is prime minister?'}]\n"},{"output_type":"stream","name":"stderr","text":"Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n"},{"output_type":"execute_result","execution_count":8,"data":{"text/plain":["'The Prime Minister is the head of government in a country. The current Prime Minister of the United Kingdom'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{}}]},{"cell_type":"code","source":"import torch\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\nphi_id = \"microsoft/Phi-3.5-mini-instruct\"\npipeline2 = transformers.pipeline(\n    \"text-generation\",\n    model=phi_id,\n    model_kwargs={\"torch_dtype\": torch.bfloat16, \"quantization_config\" : {\"load_in_4bit\": True}},\n    device_map=\"auto\",\n    \n)\n\ndef phi_output(prompt, tokens):\n    messages = [\n        {\"role\": \"user\", \"content\": prompt},\n    ]\n#     print(messages)\n    outputs = pipeline2(\n        messages,\n        max_new_tokens=tokens,\n    )\n    return outputs[0][\"generated_text\"][-1][\"content\"]","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["ad56d8400207459d83da899ae5d2785d","fdf5cddce7d64bbeb936991983ec4f51","cb9b7741307d45ce9c586c0efa547cca","b1ed3baac33b4aa2ac79b835ed9336d1","24988250c1ff4dd3afed146d6712d24b","6bf7d79d806447fb99c0404b584e3ff0","52b61171ec654209b43666ea8be662a7","f94fbb248dd14a8692ef264520511ab9","fd13f5c81b50496090656466e1ebe8ce","4703c2d74de842879ec0c7a2850e1559","ed1fd931bc32413ebb0e18a664464c2d"]},"id":"t_r0ypUX1yvz","outputId":"e67a6d6a-4842-4295-b734-a647699b3981","execution":{"iopub.status.busy":"2024-09-18T18:28:54.094412Z","iopub.execute_input":"2024-09-18T18:28:54.095365Z","iopub.status.idle":"2024-09-18T18:29:47.531289Z","shell.execute_reply.started":"2024-09-18T18:28:54.095317Z","shell.execute_reply":"2024-09-18T18:29:47.529840Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/3.45k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b305ba988ec04e97bedf54f64cb83c40"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/16.3k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c5f5362cec04c59bfcab3d031f5eff0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"244b39bf0bf845e59db056ef0664b6aa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"527802b8caaa4f0a8847698503126454"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/2.67G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f9023f442534c61b520759b6948d696"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7cdba8a18ad6420a93e25e1135f3e259"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/195 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"41934db81a5447218b915215d4f30c3e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/3.98k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"67e4a608d99f4768927e89675758ab64"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bcab55ebb892462a8d121c73af6bb53f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0fb25abbac124edb8e26afbe15a31a52"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/306 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"921397757aae4facbc55c93ff512c204"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0224ddd9d3c34e1d970a9cd7d451024e"}},"metadata":{}}]},{"cell_type":"code","source":"import torch\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n\ngemma_id = \"google/gemma-2b-it\"\npipeline3 = transformers.pipeline(\n    \"text-generation\",\n    model=gemma_id,\n    model_kwargs={\"torch_dtype\": torch.bfloat16, \"quantization_config\" : {\"load_in_4bit\": True}},\n    device_map=\"auto\",\n\n)\n\ndef gemma_output(prompt, tokens):\n    messages = [\n        {\"role\": \"user\", \"content\": prompt},\n    ]\n#     print(messages)\n    outputs = pipeline3(\n        messages,\n        max_new_tokens=tokens,\n    )\n    return outputs[0][\"generated_text\"][-1][\"content\"]","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":122,"referenced_widgets":["9c70099f3aa54ab8b582dcda4d829c01","6b7f0bd46fb9476db41d92f18d286863","a79d786f23dc4a07b28731e7f7b4828e","ff7d082b25d24c86923fcfb08e41e984","8525bc37d6ca44daa5bc6466e9a12b58","1012ef89c4784c1da84dac0664432ed3","e56928616e0b453c92ca024128cde77e","ca97228d8bfb47ebb1037bea599e0a82","dd17fc3443264074bc663ae0d4e0f1b9","31094c09960047cdb877880bafffb401","a8ec691a7dbf4f3c8390901f7b383730"]},"id":"YlA27yc51yv0","outputId":"f7e883bd-00ee-4a99-df53-521af6aa6223","execution":{"iopub.status.busy":"2024-09-18T18:31:58.783046Z","iopub.execute_input":"2024-09-18T18:31:58.783812Z","iopub.status.idle":"2024-09-18T18:32:45.458159Z","shell.execute_reply.started":"2024-09-18T18:31:58.783745Z","shell.execute_reply":"2024-09-18T18:32:45.457195Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/627 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"acb9d4670e7c49fdb79753ea1b13e02d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/13.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c4322e4c9ef54192adf07279198c0bc1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"50c6bc622863414e8a89725f85dfd877"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e1fb63cbd9fc44e79e0b77a4907da89e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/67.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f44df8e3b3b34977bb6d8898d5a7f3da"}},"metadata":{}},{"name":"stderr","text":"`config.hidden_act` is ignored, you should use `config.hidden_activation` instead.\nGemma's activation function will be set to `gelu_pytorch_tanh`. Please, use\n`config.hidden_activation` if you want to override this behaviour.\nSee https://github.com/huggingface/transformers/pull/29402 for more details.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ddb3b2dabfe44f97b2d2cc0f8ea722bc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/137 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"040f0cde924e4219982ec1084c75106d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/34.2k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c10bc470dfee4785837d2599f63488cf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/4.24M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"16e1346bbee34b42ba6245ff1b92c439"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e90ff995f7bd46088ce6545a35d6743c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/636 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dd3421ade64a429c8bc907a1c7d34b56"}},"metadata":{}}]},{"cell_type":"code","source":"!pip install datasets\nfrom datasets import load_dataset\n\nds = load_dataset(\"cais/mmlu\", \"college_mathematics\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6JqF4SiJ1yv0","outputId":"b53e71a3-d10c-48b6-f7a8-bba53d563d68","execution":{"iopub.status.busy":"2024-09-18T18:14:25.924448Z","iopub.execute_input":"2024-09-18T18:14:25.925458Z","iopub.status.idle":"2024-09-18T18:14:48.979026Z","shell.execute_reply.started":"2024-09-18T18:14:25.925414Z","shell.execute_reply":"2024-09-18T18:14:48.978068Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.21.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.15.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (16.1.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.2)\nRequirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.5)\nRequirement already satisfied: huggingface-hub>=0.21.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.24.6)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (24.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.2)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.2->datasets) (4.12.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2024.7.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/53.2k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a973da36430495bba68c5a1f550d2f5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading metadata:   0%|          | 0.00/138k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb5b3d0989e240f2989db692cbdf3a7b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/16.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"facd0b5ad9ce475aa6a4b3d884937dc3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/5.00k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f35d247e1954097a6181fc9f27a2b6f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/5.16k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"32fbad3d706e4cc38589259cc95e825b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/100 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"37ce7f1e83bf4ef49b394771f77a77cb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/11 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a8125b07ee224e8da2e72e39efb1eb23"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating dev split:   0%|          | 0/5 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d9b16b615fa4521a8c655f44d474257"}},"metadata":{}}]},{"cell_type":"code","source":"print(ds['test'][63]['answer'])","metadata":{"execution":{"iopub.status.busy":"2024-09-18T18:36:00.022868Z","iopub.execute_input":"2024-09-18T18:36:00.023270Z","iopub.status.idle":"2024-09-18T18:36:00.028930Z","shell.execute_reply.started":"2024-09-18T18:36:00.023235Z","shell.execute_reply":"2024-09-18T18:36:00.027903Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"3\n","output_type":"stream"}]},{"cell_type":"code","source":"zeroshot_prompts = []\ncot_prompts = []\nfor i in range(100):\n    zshot = f'''\nChoose the answer to the given question from below options.\nQuestion: {ds['test'][i]['question']}\noption 1: {ds['test'][i]['choices'][0]}\noption 2: {ds['test'][i]['choices'][1]}\noption 3: {ds['test'][i]['choices'][2]}\noption 4: {ds['test'][i]['choices'][3]}\n\nJust output the correct option number like: option 1, option 2, option 3, option 4 without any explanation.'''\n    cot= f'''\nChoose the answer to the given question from below options.\nQuestion: {ds['test'][i]['question']}\noption 1: {ds['test'][i]['choices'][0]}\noption 2: {ds['test'][i]['choices'][1]}\noption 3: {ds['test'][i]['choices'][2]}\noption 4: {ds['test'][i]['choices'][3]}\n\nExplain step by step and then Output the correct option number like: option 1, option 2, option 3, option 4.'''\n    zeroshot_prompts.append(zshot)\n    cot_prompts.append(cot)\nprint(zeroshot_prompts[0])\nprint(cot_prompts[1])","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wpFQWtum1yv0","outputId":"28e389cd-6e99-40f2-8513-1c50b48666b2","execution":{"iopub.status.busy":"2024-09-18T18:33:55.044962Z","iopub.execute_input":"2024-09-18T18:33:55.045747Z","iopub.status.idle":"2024-09-18T18:33:55.142076Z","shell.execute_reply.started":"2024-09-18T18:33:55.045706Z","shell.execute_reply":"2024-09-18T18:33:55.141161Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"\nChoose the answer to the given question from below options.\nQuestion: Let k be the number of real solutions of the equation e^x + x - 2 = 0 in the interval [0, 1], and let n be the number of real solutions that are not in [0, 1]. Which of the following is true?\noption 1: k = 0 and n = 1\noption 2: k = 1 and n = 0\noption 3: k = n = 1\noption 4: k > 1\n\nJust output the correct option number like: option 1, option 2, option 3, option 4 without any explanation.\n\nChoose the answer to the given question from below options.\nQuestion: Up to isomorphism, how many additive abelian groups G of order 16 have the property that x + x + x + x = 0 for each x in G ?\noption 1: 0\noption 2: 1\noption 3: 2\noption 4: 3\n\nExplain step by step and then Output the correct option number like: option 1, option 2, option 3, option 4.\n","output_type":"stream"}]},{"cell_type":"code","source":"print(cot_prompts[63])\nllama_output(cot_prompts[63],1024)\n# phi_output(cot_prompts[63],200)\n# gemma_output(cot_prompts[63],200)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":257},"id":"ptCx_AOs1yv0","outputId":"3f359c7f-2cd3-4a32-bf28-ceb2f17d9f47","execution":{"iopub.status.busy":"2024-09-18T18:34:30.062345Z","iopub.execute_input":"2024-09-18T18:34:30.062746Z","iopub.status.idle":"2024-09-18T18:35:02.070663Z","shell.execute_reply.started":"2024-09-18T18:34:30.062709Z","shell.execute_reply":"2024-09-18T18:35:02.069725Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"\nChoose the answer to the given question from below options.\nQuestion: In a game two players take turns tossing a fair coin; the winner is the first one to toss a head. The probability that the player who makes the first toss wins the game is\noption 1: 1/4\noption 2: 1/3\noption 3: 1/2\noption 4: 2/3\n\nExplain step by step and then Output the correct option number like: option 1, option 2, option 3, option 4.\n","output_type":"stream"},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"\"To solve this problem, let's break it down step by step:\\n\\n1. The game starts with player A's turn. The probability of player A getting a head on the first toss is 1/2.\\n\\n2. If player A gets a tail, the game moves to player B's turn. The probability of this happening is 1/2.\\n\\n3. Now, the game starts with player B's turn. The probability of player B getting a head on the first toss is 1/2.\\n\\n4. If player B gets a tail, the game moves to player A's turn again. The probability of this happening is 1/2.\\n\\n5. Now, the game starts with player A's turn again. The probability of player A getting a head on the first toss is 1/2.\\n\\n6. If player A gets a tail, the game moves to player B's turn again. The probability of this happening is 1/2.\\n\\n7. Now, the game starts with player B's turn again. The probability of player B getting a head on the first toss is 1/2.\\n\\nNotice a pattern here? The game will keep alternating between player A and player B until one of them gets a head.\\n\\n8. The probability of player A winning the game is the sum of the probabilities of the following events:\\n   - Player A gets a head on the first toss (1/2)\\n   - Player A gets a tail on the first toss, player B gets a tail on the first toss, and player A gets a head on the third toss (1/2 * 1/2 * 1/2)\\n   - Player A gets a tail on the first toss, player B gets a head on the first toss, player A gets a tail on the third toss, and player B gets a head on the fifth toss (1/2 * 1/2 * 1/2 * 1/2)\\n   - And so on...\\n\\nThis is an infinite geometric series with first term 1/2 and common ratio 1/2 * 1/2 = 1/4. The sum of this series is (1/2) / (1 - 1/4) = (1/2) / (3/4) = 2/3.\\n\\nSo, the probability that the player who makes the first toss wins the game is 2/3.\\n\\nOutput: option 4.\""},"metadata":{}}]},{"cell_type":"code","source":"from tqdm import tqdm\nimport pickle\nc_llama, c_phi, c_gemma = [],[],[]\ncot = []\nfor i in tqdm(range(100)):\n    a1 = llama_output(cot_prompts[i],1024)\n    a2 = phi_output(cot_prompts[i],1024)\n    a3 = gemma_output(cot_prompts[i],1024)\n    c_llama.append(a1)\n    c_phi.append(a2)\n    c_gemma.append(a3)\n\nwith open('Llama_cot.pkl', 'wb') as f:\n    pickle.dump(c_llama, f)\nwith open('Phi_cot.pkl', 'wb') as f:\n    pickle.dump(c_phi, f)\nwith open('Gemma_cot.pkl', 'wb') as f:\n    pickle.dump(c_gemma, f)\n\nprint(\"Pickled lists saved successfully.\")\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HKQTJHPe1yv1","outputId":"3cb8ee0e-cd9e-48a6-885c-18a5ee66de17","execution":{"iopub.status.busy":"2024-09-18T18:38:05.529049Z","iopub.execute_input":"2024-09-18T18:38:05.529960Z","iopub.status.idle":"2024-09-18T20:46:04.510326Z","shell.execute_reply.started":"2024-09-18T18:38:05.529921Z","shell.execute_reply":"2024-09-18T20:46:04.509257Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"  0%|          | 0/100 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\nStarting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n  1%|          | 1/100 [01:08<1:52:14, 68.03s/it]You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n  2%|▏         | 2/100 [02:47<2:21:23, 86.57s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n  3%|▎         | 3/100 [04:42<2:40:54, 99.53s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n  4%|▍         | 4/100 [06:28<2:43:21, 102.10s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n  5%|▌         | 5/100 [07:31<2:19:18, 87.98s/it] Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n  6%|▌         | 6/100 [09:25<2:31:26, 96.66s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n  7%|▋         | 7/100 [11:11<2:34:48, 99.88s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n  8%|▊         | 8/100 [12:18<2:17:13, 89.50s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n  9%|▉         | 9/100 [13:43<2:13:35, 88.08s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 10%|█         | 10/100 [14:12<1:44:44, 69.83s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 11%|█         | 11/100 [14:40<1:24:31, 56.98s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 12%|█▏        | 12/100 [16:19<1:42:26, 69.84s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 13%|█▎        | 13/100 [17:08<1:31:58, 63.43s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 14%|█▍        | 14/100 [18:08<1:29:38, 62.54s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 15%|█▌        | 15/100 [19:16<1:30:43, 64.04s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 16%|█▌        | 16/100 [19:55<1:19:07, 56.52s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 17%|█▋        | 17/100 [21:16<1:28:10, 63.74s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 18%|█▊        | 18/100 [22:13<1:24:30, 61.83s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 19%|█▉        | 19/100 [23:56<1:40:11, 74.21s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 20%|██        | 20/100 [24:46<1:29:14, 66.93s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 21%|██        | 21/100 [25:57<1:29:33, 68.01s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 22%|██▏       | 22/100 [28:16<1:56:23, 89.53s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 23%|██▎       | 23/100 [29:17<1:43:42, 80.81s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 24%|██▍       | 24/100 [30:49<1:46:34, 84.14s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 25%|██▌       | 25/100 [31:32<1:29:50, 71.87s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 26%|██▌       | 26/100 [32:36<1:25:36, 69.41s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 27%|██▋       | 27/100 [34:39<1:44:05, 85.55s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 28%|██▊       | 28/100 [35:31<1:30:43, 75.60s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 29%|██▉       | 29/100 [37:30<1:44:40, 88.46s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 30%|███       | 30/100 [38:30<1:33:20, 80.01s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 31%|███       | 31/100 [39:26<1:23:50, 72.91s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 32%|███▏      | 32/100 [41:50<1:46:50, 94.27s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 33%|███▎      | 33/100 [42:43<1:31:29, 81.93s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 34%|███▍      | 34/100 [44:21<1:35:14, 86.58s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 35%|███▌      | 35/100 [45:26<1:26:47, 80.12s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 36%|███▌      | 36/100 [47:42<1:43:15, 96.80s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 37%|███▋      | 37/100 [48:33<1:27:18, 83.15s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 38%|███▊      | 38/100 [49:22<1:15:22, 72.94s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 39%|███▉      | 39/100 [50:26<1:11:21, 70.19s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 40%|████      | 40/100 [51:54<1:15:28, 75.48s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 41%|████      | 41/100 [52:38<1:05:01, 66.13s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 42%|████▏     | 42/100 [53:52<1:06:17, 68.59s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 43%|████▎     | 43/100 [54:38<58:44, 61.84s/it]  Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 44%|████▍     | 44/100 [56:19<1:08:28, 73.37s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 45%|████▌     | 45/100 [57:23<1:04:40, 70.55s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 46%|████▌     | 46/100 [58:04<55:38, 61.83s/it]  Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 47%|████▋     | 47/100 [59:36<1:02:28, 70.72s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 48%|████▊     | 48/100 [1:00:29<56:40, 65.39s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 49%|████▉     | 49/100 [1:01:38<56:29, 66.46s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 50%|█████     | 50/100 [1:02:27<51:09, 61.39s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 51%|█████     | 51/100 [1:03:08<45:08, 55.28s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 52%|█████▏    | 52/100 [1:04:10<45:54, 57.38s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 53%|█████▎    | 53/100 [1:05:09<45:08, 57.62s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 54%|█████▍    | 54/100 [1:06:21<47:29, 61.95s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 55%|█████▌    | 55/100 [1:07:38<50:00, 66.69s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 56%|█████▌    | 56/100 [1:08:19<43:14, 58.96s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 57%|█████▋    | 57/100 [1:09:25<43:44, 61.02s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 58%|█████▊    | 58/100 [1:10:10<39:17, 56.14s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 59%|█████▉    | 59/100 [1:12:18<53:09, 77.79s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 60%|██████    | 60/100 [1:13:56<55:54, 83.86s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 61%|██████    | 61/100 [1:15:13<53:05, 81.69s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 62%|██████▏   | 62/100 [1:16:27<50:23, 79.55s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 63%|██████▎   | 63/100 [1:18:03<52:06, 84.51s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 64%|██████▍   | 64/100 [1:19:44<53:31, 89.22s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 65%|██████▌   | 65/100 [1:21:18<52:56, 90.75s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 66%|██████▌   | 66/100 [1:23:05<54:15, 95.76s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 67%|██████▋   | 67/100 [1:24:38<52:11, 94.90s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 68%|██████▊   | 68/100 [1:26:23<52:10, 97.82s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 69%|██████▉   | 69/100 [1:28:14<52:33, 101.74s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 70%|███████   | 70/100 [1:29:05<43:18, 86.62s/it] Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 71%|███████   | 71/100 [1:30:36<42:29, 87.91s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 72%|███████▏  | 72/100 [1:32:02<40:45, 87.34s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 73%|███████▎  | 73/100 [1:33:04<35:49, 79.60s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 74%|███████▍  | 74/100 [1:34:39<36:35, 84.44s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 75%|███████▌  | 75/100 [1:36:27<38:03, 91.35s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 76%|███████▌  | 76/100 [1:37:47<35:09, 87.91s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 77%|███████▋  | 77/100 [1:38:44<30:10, 78.73s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 78%|███████▊  | 78/100 [1:40:47<33:42, 91.94s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 79%|███████▉  | 79/100 [1:41:45<28:37, 81.78s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 80%|████████  | 80/100 [1:42:39<24:29, 73.49s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 81%|████████  | 81/100 [1:43:36<21:43, 68.59s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 82%|████████▏ | 82/100 [1:44:44<20:29, 68.29s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 83%|████████▎ | 83/100 [1:46:23<21:59, 77.63s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 84%|████████▍ | 84/100 [1:47:13<18:29, 69.36s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 85%|████████▌ | 85/100 [1:49:08<20:46, 83.08s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 86%|████████▌ | 86/100 [1:49:56<16:52, 72.29s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 87%|████████▋ | 87/100 [1:50:51<14:33, 67.19s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 88%|████████▊ | 88/100 [1:52:25<15:04, 75.35s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 89%|████████▉ | 89/100 [1:53:35<13:30, 73.70s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 90%|█████████ | 90/100 [1:54:48<12:14, 73.43s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 91%|█████████ | 91/100 [1:55:57<10:48, 72.10s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 92%|█████████▏| 92/100 [1:57:09<09:36, 72.08s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 93%|█████████▎| 93/100 [1:59:27<10:44, 92.04s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 94%|█████████▍| 94/100 [2:00:42<08:41, 86.92s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 95%|█████████▌| 95/100 [2:01:28<06:13, 74.63s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 96%|█████████▌| 96/100 [2:02:26<04:37, 69.44s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 97%|█████████▋| 97/100 [2:03:29<03:22, 67.55s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 98%|█████████▊| 98/100 [2:04:55<02:26, 73.23s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n 99%|█████████▉| 99/100 [2:06:49<01:25, 85.26s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n100%|██████████| 100/100 [2:07:58<00:00, 76.79s/it]","output_type":"stream"},{"name":"stdout","text":"Pickled lists saved successfully.\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"id":"81cLNQWp-IEh"},"execution_count":null,"outputs":[]}]}
